"""
Configuration file - System parameters and LLM settings

Supports BOTH OpenAI and OpenRouter APIs:
- Set OPENAI_API_KEY for direct OpenAI access (recommended, lower latency)
- Set OPENROUTER_API_KEY for OpenRouter gateway (access to multiple models)

Provider is auto-detected based on which environment variable is set.
OpenAI takes precedence if both are set.
"""

import os

# ============================================================================
# Provider Auto-Detection
# ============================================================================

# Detect which provider to use based on available API keys
_openai_key = os.environ.get("OPENAI_API_KEY", "")
_openrouter_key = os.environ.get("OPENROUTER_API_KEY", "")

# Determine active provider (OpenAI takes precedence)
if _openai_key:
    API_KEY = _openai_key
    BASE_URL = "https://api.openai.com/v1"
    LLM_MODEL = "gpt-4.1-mini"
    EMBEDDING_MODEL = "text-embedding-3-small"
    EMBEDDING_DIMENSION = 1536
    _PROVIDER = "openai"
elif _openrouter_key:
    API_KEY = _openrouter_key
    BASE_URL = "https://openrouter.ai/api/v1"
    LLM_MODEL = "openai/gpt-4.1-mini"
    EMBEDDING_MODEL = "qwen/qwen3-embedding-8b"
    EMBEDDING_DIMENSION = 4096
    _PROVIDER = "openrouter"
else:
    # No API key - defaults to OpenAI (will fail on first API call)
    API_KEY = ""
    BASE_URL = "https://api.openai.com/v1"
    LLM_MODEL = "gpt-4.1-mini"
    EMBEDDING_MODEL = "text-embedding-3-small"
    EMBEDDING_DIMENSION = 1536
    _PROVIDER = "none"

# Legacy variable names for backward compatibility with existing code
OPENROUTER_API_KEY = API_KEY
OPENROUTER_BASE_URL = BASE_URL


# ============================================================================
# Advanced Settings
# ============================================================================

# Temperature for LLM responses (0.0 = deterministic, 2.0 = very random)
TEMPERATURE = 0.1

# Maximum tokens for LLM responses (None = model default)
MAX_TOKENS = None


# ============================================================================
# Memory Building Parameters
# ============================================================================

# Number of dialogues per window (for locomo; for other dataset, please finetune it)
WINDOW_SIZE = 40

# Window overlap size (for context continuity)
OVERLAP_SIZE = 2


# ============================================================================
# Retrieval Parameters
# ============================================================================

# Max entries returned by semantic search (vector similarity)
SEMANTIC_TOP_K = 25

# Max entries returned by keyword search (BM25 matching)
KEYWORD_TOP_K = 5

# Max entries returned by structured search (metadata filtering)
STRUCTURED_TOP_K = 5


# ============================================================================
# Database Configuration
# ============================================================================

# Path to LanceDB storage (relative to skill root)
LANCEDB_PATH = "./data/lancedb"

# Memory table name
MEMORY_TABLE_NAME = "memory_entries"


# ============================================================================
# Parallel Processing Configuration
# ============================================================================

# Memory Building Parallel Processing
ENABLE_PARALLEL_PROCESSING = True
MAX_PARALLEL_WORKERS = 16

# Retrieval Parallel Processing
ENABLE_PARALLEL_RETRIEVAL = True
MAX_RETRIEVAL_WORKERS = 8

# Planning and Reflection Configuration
ENABLE_PLANNING = True
ENABLE_REFLECTION = True
MAX_REFLECTION_ROUNDS = 2
